{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOSK Speech Recognition Feature Extraction\n",
    "\n",
    "|Category(ies)         |References            |Input Type            |Workflows             |Next Steps            |\n",
    "|----------------------|----------------------|----------------------|----------------------|----------------------|\n",
    "|feature extraction|[dps repo](https://github.com/jdchart/dps)|results of a speech recognition anlysis|||\n",
    "\n",
    "In this notebook, we'll take a \"raw\" speech recognition analysis of an audio file, and extract a number of different features from it. Many of these features we're developed in the context of ThÃ©o Heugebaert's PhD on rhythm in the performing arts, and are part of the [dps python package](https://github.com/jdchart/dps.git) which was designed for his project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "First, let's import all of the various packages that we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip cache purge > /dev/null 2>&1\n",
    "!pip uninstall -y jlu > /dev/null 2>&1\n",
    "!pip install -q git+https://github.com/arvest-data-in-context/jlu > /dev/null 2>&1\n",
    "!pip uninstall -y dps > /dev/null 2>&1\n",
    "!pip install -q git+https://github.com/jdchart/dps.git > /dev/null 2>&1\n",
    "import os\n",
    "import jlu\n",
    "import dps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load VOSK Analysis\n",
    "Here we shall load the json output of the VOSK analyses we wish to process. Note that this notebook is specifically tailored to extract features from the VOSK speech recognition notebook in this collection of notebooks, however it wouldn't take much to adjust it for the output of another speech recognition model. Change the `VOSK_ANALYSES` variable to the folder that contains the analyses you wish to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOSK_ANALYSES = os.path.join(os.path.abspath('../../..'), \"output\")\n",
    "analysis_files = jlu.files.collect_files(VOSK_ANALYSES, [\"json\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "Now we can use the [dps python package](https://github.com/jdchart/dps.git) to extract the various features. We shall do this for each file.\n",
    "\n",
    "Before we process everything, let's just take a closer look at one instance in order to understand what's happening under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load the analysis file in the dps.SpeechAnalysis() class\n",
    "speech_recognition = dps.SpeechAnalysis(analysis_files[0])\n",
    "\n",
    "# This will have already parsed the data into a raw curve which can be visualized:\n",
    "speech_recognition.display_raw_curve(0)\n",
    "speech_recognition.display_raw_curve(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each feature has a number of different parameters. You can extract as many features as you wish, with varying different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can extract features like dps as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dps across a region:\n",
    "print(speech_recognition.get_dps())\n",
    "print(speech_recognition.get_dps(region = {\"start_ms\" : 0, \"end_ms\" : 92000}))\n",
    "print(speech_recognition.get_dps(region = {\"start_ms\" : 0, \"end_ms\" : 40000}))\n",
    "print(speech_recognition.get_dps(region = {\"start_ms\" : 40000, \"end_ms\" : 92000}))\n",
    "\n",
    "# Get DPS as a feature curve:\n",
    "dps_curve = speech_recognition.get_dps_feature_curve(128, 4)\n",
    "# Visualize:\n",
    "plt.figure(figsize=(10, 6))\n",
    "frame_numbers = np.arange(len(dps_curve))\n",
    "plt.plot(frame_numbers, dps_curve, drawstyle='steps-post')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('DPS')\n",
    "plt.title('DPS Curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
